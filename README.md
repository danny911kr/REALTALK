# REALTALK: A 21-Day Real-World Dataset for Long-Term Conversation

[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-green.svg?style=flat-square)](http://makeapullrequest.com)  
[![arXiv](https://img.shields.io/badge/arXiv-2502.13270-b31b1b.svg)](https://arxiv.org/abs/2502.13270)

This repository contains the dataset, models, and evaluation code from our paper:  
**[REALTALK: A 21-Day Real-World Dataset for Long-Term Conversation](https://arxiv.org/abs/2502.13270)**

---

## ğŸ” Continuation of LoCoMo

REALTALK builds upon our previous work **LoCoMo**, a synthetic dataset generated by LLMs for simulating long-term dialogue. 
While LoCoMo provided a controlled sandbox for exploring memory and persona behavior, **REALTALK offers real-world complexity**, drawn from human conversations across 21 days.

ğŸ“„ **LoCoMo (LLM-generated benchmark):**  
- Paper: [https://arxiv.org/abs/2402.17753](https://arxiv.org/abs/2402.17753)  
- Website: [https://snap-research.github.io/locomo/](https://snap-research.github.io/locomo/)  
- Code: [https://github.com/snap-research/LoCoMo](https://github.com/snap-research/LoCoMo)

---

## ğŸ“š Overview

Long-term, open-domain dialogue is critical for building conversational agents capable of demonstrating **emotional intelligence (EI)** and **recalling past interactions**. However, most existing benchmarks rely on synthetic, LLM-generated data, which lacks the depth, messiness, and variability of real conversations.

To address this gap, we introduce **REALTALK**: a 21-day corpus of **authentic, real-world messaging app conversations** between human participants. This enables a more rigorous evaluation of dialogue models in naturalistic settings.

### ğŸ§  Key Contributions
- A **real-world long-form dialogue dataset** with emotional grounding and time-span variation.
- Comparative analysis of **emotional expression** and **persona consistency** between REALTALK and LLM-generated dialogues (LoCoMo).
- Two benchmark tasks designed for long-term conversation evaluation:
  1. **Persona Simulation** â€“ continue a chat as a specific user based on past messages.
  2. **Memory Probing** â€“ answer questions that require recalling facts from earlier interactions.

---

## ğŸ“ Table of Contents

1. [Setup](#setup)
2. [Data](#data)
3. [Tasks](#tasks)
   - [Persona Simulation](#persona-simulation)
   - [Memory Probing](#memory-probing)

---

## âš™ï¸ Setup

Set your OpenAI API key for memory probing tasks:
```bash
export OPENAI_API_KEY=sk-...
```

---

## ğŸ“¦ Data

- `data/*.json`: Preprocessed REALTALK conversations (for evaluation and model input).
- `data/raw/*.xlsx`: Raw message exports used to construct the dataset.

---

## ğŸ§ª Tasks

### ğŸ—£ï¸ Persona Simulation (Coming soon)

> Given previous conversation history, continue the dialogue as one of the original participants.  
Code and model evaluation details will be released shortly.

---

### ğŸ§  Memory Probing

> Assess how well a model remembers facts from earlier parts of a long conversation.

#### ğŸ”§ Run evaluation:
```bash
python evaluate_memory.py \
    --data_path data/Chat_1_Emi_Elise.json \
    --qa_model gpt-4o-mini \
    --evaluate_model gpt-4o-mini
```

#### ğŸ“ Argument details:
- `--qa_model`: The model used to generate answers to the probing questions.
- `--evaluate_model`: The model used to assign a **GPT score**.  
  A **lexical F1 score** is also computed as a rule-based measure.

